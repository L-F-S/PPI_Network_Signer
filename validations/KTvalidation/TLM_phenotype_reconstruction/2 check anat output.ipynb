{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a8d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Reformats ANAT network output\n",
    "\n",
    "python 2get_subnets.py terminal1 terminaln ... anchor ANATfilenameWithoutextension\n",
    "\n",
    "creates a .path pkl file of a dictionary of paths per terminal\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import collections\n",
    "import itertools\n",
    "import lxml.etree as etree\n",
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import seed, sample\n",
    "from datetime import date\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "SPECIES = \"S_cerevisiae\"\n",
    "# SPECIES='H_sapiens'\n",
    "DATE=str(date.today().strftime(\"%d/%m/%Y\"))\n",
    "HOME_DIR='G:'+os.sep+'Il Mio Drive'+os.sep+'SECRET-ITN'+os.sep+'Projects'+os.sep+\\\n",
    "    'network_signing'+os.sep+'Validations'+os.sep+'ANAT_validation_pipeline'+os.sep\n",
    "#HOME_DIR='G:'+os.sep+'My Drive'+os.sep+'SECRET-ITN'+os.sep+'Projects'+os.sep+\\\n",
    " #   'network_signing'+os.sep+'SIGNAL Validations target sign reconstruction'\\\n",
    "  #      +os.sep+'ANAT_validation_pipeline'+os.sep\n",
    "MAIN_DATA_DIR = 'G:'+os.sep+'Il Mio Drive'+os.sep+'SECRET-ITN'+os.sep+'Projects'+os.sep+'Data'+os.sep+SPECIES+os.sep\n",
    "#MAIN_DATA_DIR = 'G:'+os.sep+'My Drive'+os.sep+'SECRET-ITN'+os.sep+'Projects'+os.sep+'Data'+os.sep+SPECIES+os.sep\n",
    "#INPUT_DIR =  HOME_DIR+ '1 Build Pacitaxel target - fosfoprotein paths'\n",
    "os.chdir(HOME_DIR)\n",
    "\n",
    "with open( MAIN_DATA_DIR+'alias_2geneid.pkl', 'rb') as f:\n",
    "    alias_2geneid = pickle.load(f)\n",
    "\n",
    "# network=pd.read_csv(MAIN_DATA_DIR +SPECIES+'.net',sep=\"\\t\", header=None)\n",
    "# graph = nx.from_pandas_edgelist(network.reset_index(), 0, 1, 2)\n",
    "f=open(HOME_DIR+'1 ANAT Build networks'+os.sep+'Input'+os.sep+'TLManchors.txt')\n",
    "lines=[x.strip() for x in f.readlines()]\n",
    "ANCHORS=lines\n",
    "f.close()\n",
    "TLMphenotypesdf=pd.read_csv(HOME_DIR+'1 ANAT Build networks'+os.sep+'Input'+os.sep+'TLMphenotypesnodupes.txt', header=0, sep='\\t')\n",
    "TERMS=list(TLMphenotypesdf[TLMphenotypesdf.columns[0]].values)\n",
    "\n",
    "    # For TUBB Paclitaxtel validaiton\n",
    "#    FILENAME = 'TUBB_v_all'\n",
    " #   ANCHORS='TUBB'\n",
    "  #  TERMS=['SMAD3','JUN','TP53','RPS6KB1','EGFR','MARCKS','PRAS40','PTP2C','IKBA',\n",
    "   #         'GSK3A','AKT1','HSPB1','H2A.X','MAPK11','MEK1','STAT3','ERK1','RSK1','CREB1','FAK1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6134dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  with networkx (has revealed the bug with TLM data)\n",
    "FILENAME='TLM_strong_normal'#'TLM_all_KOterms'#\n",
    "network_file='1 ANAT Build networks'+os.sep+'ANAT output'+os.sep+FILENAME\n",
    "\n",
    "\n",
    "# Read the CSV edges file \n",
    "columns = ['ID1', 'ID2']\n",
    "edges_df = pd.read_csv(network_file+'.csv', usecols=columns)\n",
    "graph_symbols=nx.from_pandas_edgelist(edges_df, source='ID1', target='ID2')\n",
    "\n",
    "# Read the CSV nodes file and select the desired columns and rows\n",
    "nodesfile=HOME_DIR+'1 ANAT Build networks'+os.sep+'ANAT output'+os.sep+FILENAME+'_nodes.csv'\n",
    "columns = ['name', 'status','xrefID','xrefName']\n",
    "nodes_df = pd.read_csv(nodesfile, usecols=columns)\n",
    "\n",
    "#%% v2 debugging: checking difference between ANAT output's terms and sources and original terms and sources\n",
    "with open( MAIN_DATA_DIR+'symbol_2geneid.pkl', 'rb') as f:\n",
    "    symbol_2geneid = pickle.load(f)\n",
    "id_2alias={y:x for (x,y) in symbol_2geneid.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddc7e185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking cytoscape nodes against  cytoscape edges using symbols\n",
      "qlcs non va!! Geni in NODES table not present in EDGES table: EST2\n"
     ]
    }
   ],
   "source": [
    "#%% check if some nodes in ANAT output graph are not present in ancohors or terminals\n",
    "# to do this, first check that all nodes in the nodes table from cytoscape\n",
    "# are in the edges table as well,\n",
    "\n",
    "print('checking cytoscape nodes against  cytoscape edges using symbols')\n",
    "for genename in nodes_df.xrefName:\n",
    "    if not genename in graph_symbols.nodes:\n",
    "        print('qlcs non va!! Geni in NODES table not present in EDGES table:', genename)\n",
    "for genename in graph_symbols.nodes:\n",
    "    if not genename in list(nodes_df.xrefName):\n",
    "        print('qlcs non va! geni in edges non presenti in nodes', genename)\n",
    "\n",
    "# usando questo mi rendo conto che l unico problema e' il nodo 'TEN1' o '850696'. per TLM allkoterms\n",
    "#menter per TLM strong_normal è il nodo EST2 (e infatti vedo dal network che non è riuscito a connetterlo, quindi lo elimino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa6e3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>xrefID</th>\n",
       "      <th>xrefName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TEN1</td>\n",
       "      <td>ANCHOR</td>\n",
       "      <td>850696</td>\n",
       "      <td>TEN1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  status  xrefID xrefName\n",
       "28  TEN1  ANCHOR  850696     TEN1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df[nodes_df['xrefName']=='TEN1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a3ce3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'TEN1' in [id_to_alias[int(a)] for a in ANCHORS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f92e80ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>xrefID</th>\n",
       "      <th>xrefName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>EST2</td>\n",
       "      <td>ANCHOR</td>\n",
       "      <td>851028</td>\n",
       "      <td>EST2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  status  xrefID xrefName\n",
       "97  EST2  ANCHOR  851028     EST2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df[nodes_df['xrefName']=='EST2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0afc0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check for 1:1 mapping between nodes between node file and edge file from anat cytoscape output\n",
      "# nodes from nodes file: (464, 4) # nodes from edges file: 463\n",
      "qlcs non va!! TEN1 in Nodes file but not in Edges file\n"
     ]
    }
   ],
   "source": [
    "#%% controlla che ci sia un rapporto 1:1 tra i nodi du graph_symbols e di nodes_df\n",
    "# ORA sappiamo che c'è discrepancy qunado un anchor rimane scollegato.\n",
    "print('check for 1:1 mapping between nodes between node file and edge file from anat cytoscape output')\n",
    "print('# nodes from nodes file:',nodes_df.shape,'# nodes from edges file:', len(graph_symbols.nodes) ) # discrepanza di 1, a'accettabile (?)\n",
    "\n",
    "for genename in nodes_df.xrefName:\n",
    "    if not genename in graph_symbols.nodes:\n",
    "        print('qlcs non va!!', genename, 'in Nodes file but not in Edges file')\n",
    "# controllo ridondante, TEN1 (850696) viene PERSO dall'edges file. forse xke semplicemente NON e' connesso!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76d568ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461 419\n",
      "qlcs non va! geni in terms non presenti in nodes FMP26\n",
      "qlcs non va! geni in terms non presenti in nodes IPK2\n",
      "qlcs non va! geni in terms non presenti in nodes KEM1\n",
      "qlcs non va! geni in terms non presenti in nodes MDN1\n",
      "qlcs non va! geni in terms non presenti in nodes PHO88\n",
      "qlcs non va! geni in terms non presenti in nodes SUR4\n",
      "qlcs non va! geni in terms non presenti in nodes TFP1\n",
      "qlcs non va! geni in terms non presenti in nodes TID3\n",
      "qlcs non va! geni in terms non presenti in nodes YBR284W\n",
      "qlcs non va! geni in terms non presenti in nodes YBR292C\n",
      "qlcs non va! geni in terms non presenti in nodes YDL119C\n",
      "qlcs non va! geni in terms non presenti in nodes YDR115W\n",
      "qlcs non va! geni in terms non presenti in nodes YDR532C\n",
      "qlcs non va! geni in terms non presenti in nodes YEL057C\n",
      "qlcs non va! geni in terms non presenti in nodes YGL039W\n",
      "qlcs non va! geni in terms non presenti in nodes YGR042W\n",
      "qlcs non va! geni in terms non presenti in nodes YHL012W\n",
      "qlcs non va! geni in terms non presenti in nodes YIL042C\n",
      "qlcs non va! geni in terms non presenti in nodes YIL077C\n",
      "qlcs non va! geni in terms non presenti in nodes YJR079W\n",
      "qlcs non va! geni in terms non presenti in nodes SIK1\n",
      "qlcs non va! geni in terms non presenti in nodes YMR269W\n",
      "qlcs non va! geni in terms non presenti in nodes YOL138C\n",
      "qlcs non va! geni in terms non presenti in nodes YOR008C-A\n",
      "qlcs non va! geni in terms non presenti in nodes YOR066W\n",
      "qlcs non va! geni in terms non presenti in nodes YOR235W\n",
      "qlcs non va! geni in terms non presenti in nodes YPL017C\n",
      "qlcs non va! geni in terms non presenti in nodes YPL041C\n",
      "qlcs non va! geni in terms non presenti in nodes YPL068C\n",
      "qlcs non va! geni in terms non presenti in nodes YPL105C\n",
      "qlcs non va! geni in terms non presenti in nodes YPL144W\n"
     ]
    }
   ],
   "source": [
    "#%% vediamo ora se tutti i nodi di TERMS almeno sono dentro nodes:\n",
    "print(len(TERMS),len(nodes_df[nodes_df.status=='TERMINAL']))\n",
    "for genename in list(TLMphenotypesdf[TLMphenotypesdf.columns[0]].values): # per prendere i genenames non tradotti\n",
    "    if not genename in list(nodes_df.xrefName):\n",
    "        print('qlcs non va! geni in original terms non presenti in nodes', genename)\n",
    "        # mancano cmq molti geni dei temrinals! aggiungere manualmente a ANAT e rilanciare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f27f5d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461 419\n",
      "qlcs non va! geni in terms non presenti in nodes FMP26\n",
      "qlcs non va! geni in terms non presenti in nodes IPK2\n",
      "qlcs non va! geni in terms non presenti in nodes KEM1\n",
      "qlcs non va! geni in terms non presenti in nodes MDN1\n",
      "qlcs non va! geni in terms non presenti in nodes PHO88\n",
      "qlcs non va! geni in terms non presenti in nodes SUR4\n",
      "qlcs non va! geni in terms non presenti in nodes TEN1\n",
      "qlcs non va! geni in terms non presenti in nodes TFP1\n",
      "qlcs non va! geni in terms non presenti in nodes TID3\n",
      "qlcs non va! geni in terms non presenti in nodes YBR284W\n",
      "qlcs non va! geni in terms non presenti in nodes YBR292C\n",
      "qlcs non va! geni in terms non presenti in nodes YDL119C\n",
      "qlcs non va! geni in terms non presenti in nodes YDR115W\n",
      "qlcs non va! geni in terms non presenti in nodes YDR532C\n",
      "qlcs non va! geni in terms non presenti in nodes YEL057C\n",
      "qlcs non va! geni in terms non presenti in nodes YGL039W\n",
      "qlcs non va! geni in terms non presenti in nodes YGR042W\n",
      "qlcs non va! geni in terms non presenti in nodes YHL012W\n",
      "qlcs non va! geni in terms non presenti in nodes YIL042C\n",
      "qlcs non va! geni in terms non presenti in nodes YIL077C\n",
      "qlcs non va! geni in terms non presenti in nodes YJR079W\n",
      "qlcs non va! geni in terms non presenti in nodes SIK1\n",
      "qlcs non va! geni in terms non presenti in nodes YMR269W\n",
      "qlcs non va! geni in terms non presenti in nodes YOL138C\n",
      "qlcs non va! geni in terms non presenti in nodes YOR008C-A\n",
      "qlcs non va! geni in terms non presenti in nodes YOR066W\n",
      "qlcs non va! geni in terms non presenti in nodes YOR235W\n",
      "qlcs non va! geni in terms non presenti in nodes YPL017C\n",
      "qlcs non va! geni in terms non presenti in nodes YPL041C\n",
      "qlcs non va! geni in terms non presenti in nodes YPL068C\n",
      "qlcs non va! geni in terms non presenti in nodes YPL105C\n",
      "qlcs non va! geni in terms non presenti in nodes YPL144W\n"
     ]
    }
   ],
   "source": [
    "#%% vediamo ora se tutti i nodi di TERMS almeno sono dentro il graph (alcune di ste cells potrebbero ripeters):\n",
    "print(len(TERMS),len(nodes_df[nodes_df.status=='TERMINAL']))\n",
    "for genename in list(TLMphenotypesdf[TLMphenotypesdf.columns[0]].values): # per prendere i genename s non tradotti\n",
    "    if not genename in graph_symbols.nodes:\n",
    "        print('qlcs non va! geni in terms non presenti in nodes', genename)\n",
    "        # mancano cmq molti geni dei temrinals! aggiungere manualmente a ANAT e rilanciare\n",
    "\n",
    "# AOCCHIO I GENES DELLE DUE CELLS SOPRA OSNO GLI STESSI\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da7f3274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidind path from: 850934\n"
     ]
    },
    {
     "ename": "NodeNotFound",
     "evalue": "Either source 850934 or target 852205 is not in G",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNodeNotFound\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfidind path from:\u001b[39m\u001b[38;5;124m'\u001b[39m, ANCHOR)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Find all paths from ANCHOR to each final node\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# save all shortest paths (one more layer of depth to dictionary)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m paths_per_anchor[ANCHOR] \u001b[38;5;241m=\u001b[39m {node: nx\u001b[38;5;241m.\u001b[39mshortest_path(graph, ANCHOR, node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m TERMS}\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(paths_per_anchor[ANCHOR])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfidind path from:\u001b[39m\u001b[38;5;124m'\u001b[39m, ANCHOR)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Find all paths from ANCHOR to each final node\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# save all shortest paths (one more layer of depth to dictionary)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m paths_per_anchor[ANCHOR] \u001b[38;5;241m=\u001b[39m {node: \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshortest_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mANCHOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m TERMS}\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(paths_per_anchor[ANCHOR])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\generic.py:165\u001b[0m, in \u001b[0;36mshortest_path\u001b[1;34m(G, source, target, weight, method)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Find shortest source-target path.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 165\u001b[0m         paths \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional_shortest_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdijkstra\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    167\u001b[0m         _, paths \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mbidirectional_dijkstra(G, source, target, weight)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py:221\u001b[0m, in \u001b[0;36mbidirectional_shortest_path\u001b[1;34m(G, source, target)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m G \u001b[38;5;129;01mor\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m G:\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither source \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or target \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not in G\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNodeNotFound(msg)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# call helper to do the real work\u001b[39;00m\n\u001b[0;32m    224\u001b[0m results \u001b[38;5;241m=\u001b[39m _bidirectional_pred_succ(G, source, target)\n",
      "\u001b[1;31mNodeNotFound\u001b[0m: Either source 850934 or target 852205 is not in G"
     ]
    }
   ],
   "source": [
    "paths_per_anchor ={}\n",
    "for ANCHOR in ANCHORS:\n",
    "    print('fidind path from:', ANCHOR)\n",
    "    # Find all paths from ANCHOR to each final node\n",
    "    \n",
    "    # save all shortest paths (one more layer of depth to dictionary)\n",
    "    paths_per_anchor[ANCHOR] = {node: nx.shortest_path(graph, ANCHOR, node) for node in TERMS}\n",
    "    print(paths_per_anchor[ANCHOR])\n",
    "    break\n",
    "        \n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374b35e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths_per_anchor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ANCHOR\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m850696\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m alias_paths_to \u001b[38;5;241m=\u001b[39m {id_to_alias[\u001b[38;5;28mint\u001b[39m(key)]:[id_to_alias[\u001b[38;5;28mint\u001b[39m(y)] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m val[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m (key, val) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpaths_per_anchor\u001b[49m[ANCHOR]\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths_per_anchor' is not defined"
     ]
    }
   ],
   "source": [
    "ANCHOR='850696'\n",
    "alias_paths_to = {id_to_alias[int(key)]:[id_to_alias[int(y)] for y in val[0]] for (key, val) in paths_per_anchor[ANCHOR].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613516a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
